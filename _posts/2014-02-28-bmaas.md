---
layout: post
title: "What is BMaaS?"
description: "Why ask why, try an api"
modified: 2014-02-28
category: posts
tags:
- maas
- razor
- iaas
blog: true
---

Working at an employer with diverse technological needs requires that what ever tools we use be incredibly versatile and secure. Recent development in [Puppetlabs Razor](https://github.com/puppetlabs/razor-server) has made it a viable option. 

## What is the point?
If anyone has spent any time in the datacenter managing hardware is a tricky task. Traditional provisioning is based on an unattended scripting framework that relies on core infrastructure technologies like tftp, pxelinux, dhcp, etc... Basically its about getting an OS on hardware, at thats more difficult that it sounds. 

<br />
How does one go about provisioning an OS? First a server would need to get an IP address most likely through DHCP. Within DHCP is the "next-server" and "file" options, this enables DHCP-clients to boot into an ROM image to then take further steps. Next steps are either [PXELINUX](http://www.syslinux.org/wiki/index.php/PXELINUX) or [iPXE](http://ipxe.org/) instructions. Both of these will trigger into network boot of an OS on first boot. 

## History Lesson
When I first started out as a systems engineer I was working for a "cloud" storage company before cloud was a thing. This meant LOTS of storage on physical servers. We managed many cabinets of servers and expanded our footprint quite fast. Since our systems were RedHat based, we relied mostly on traditional kickstarting frameworks using DHCP, TFTP, PXELINUX, Kickstart (anaconda) and a MESS of bash. This worked well for us at the time. Configuration was simply configuring DHCPD with the MAC address for each server to an Kick IP, PXELINUX config associating the HEX of the Kick IP to pxelinux.cfg for the OS and a config file associating an Kick IP address to a hostname and Dest IP.
<br />
<br />
As nice as this was it was a difficult task to configure more than 10 servers at a time. You had to collect the MACs either with iDRAC/iLO or shipping labels. The configuring of DHCPD is a manual process(retrieving Kick IP, config entry, etc..) as were ther PXELINUX and config file changes. Automation was attempted but nothing as very clean and grabbing MACs slowed the whole process WAY down. This is what I consider an Instruction-based provisioning tool. The tool itself doesn't have a way to identify hardware and make a decision and the configuration isn't separated from the hardware. When you get to an organization where you need to provision hundreds of systems, Instruction-based tools begin to lose there benefits.

<br />
To manage the complexity of provisioning there are a number of application stacks to choose from. Below is a list of tools stacks used.  

#### Below is a list of common tools:
* [Razor](https://github.com/puppetlabs/razor-server) - Extensible ruby-based provisioning tool
* [MaaS](https://maas.ubuntu.com/) - Ubuntu BareMetal provisioning
* [Crowbar](http://crowbar.github.io/home.html) - Cluster provisioning
* [StackIQ](http://www.stackiq.com/) - Cluster-based Provisioning
* [Cobbler](http://www.cobblerd.org/) - Kickstart application
* [Rocks](http://www.rocksclusters.org/wordpress/) - HPC Appliance provisioning
* [WDS](http://en.wikipedia.org/wiki/Windows_Deployment_Services) - Windows Distribution Services
* [Fog Project](http://www.fogproject.org/?q=node/1) - Free Provisioning 
* [theForeman](http://theforeman.org/) - BareMetal/Virtual Lifecycle for puppet

## What if there was a better way?

Where I work, we have hundreds of systems. I mean LOTS, like 10x what I had at the storage company. As of this week we have ~100 systems that need an OS. I was able to provision them with nothing more than turning them on and associating the Serial number with a name and IP. About 20 minutes later 80 servers have an OS and are ready for use. This is the benefit of a Discovery-Based provisioning system. 
<br />
<br />

### Basic concept:

Below is the explanation of a Discovery-based Provisioning workflow:
![]({{ site.url }}/assets/images/BMaaS-workflow.png)

#### Discovery
1. Provisioning Server is built and all services turned on.
2. New hardware is racked and powered on. 
3. Hardware PXE boots using DHCP, TFTP and iPXE. 
4. iPXE chainloads and checks into Provisioning Server.
5. iPXE lastly loads in-memory OS onto hardware. 
6. In-memory OS collects facts about hardware and posts to Provisioning server. 
7. Waits for next steps.

#### Config
1. Collect available hardware nodes from provisioning server.
2. Associates OS and node information to hardware from the available nodes.
3. Post config to Provisioning server.

#### Provisiong
1. Config is posted to Provisioning server, altering the "next steps" for each node.
2. Nodes check in for next steps and instructions are given to restart.
3. On next PXE boot server chainload iPXE again but instead of the in-memory OS, it loads the install instructions. 
4. OS is installed according to configured recipe
5. New OS on hardware registers that it has completed its install to the Provisioning server closing the loop.
6. Broker hand-off is initiated. 

### Profiles
A little bit of scripting at the Config step and you could be capable of building hundreds of servers quickly and precisely. Even better some provisioning tools are designed to provision based on a policy. By this I mean you setup a list of parameters that need to be met for a particular OS to be installed. These policies are designed to increment servers that match, so for each server attempting to install the hostname and IP increment up. So say a policy will trigger if the hardware has 4 Hex-Core Processors and 192GB RAM, if matched it will install a hypervisor. For organizations that deal with large clusters of the same hardware, this can be incredibly powerful. Rack and power and in 30 minutes an OS will be installed. 

## What about the app?
The app would be the most difficult aspect to install. Countless tools have been built to accomplish this feat and in my mind not a challenge that provisioning needs to tackle. For the customer that are looking to do one thing and one thing well, then a all-in-one provisioner makes immense sense. When your needs range from lots of different hardware, every version of OS one can image and every imaginable application stack makes a all-in-one tool nigh impossible. A good provisioning tool should offer a method to integrate with modern configuration management tools or clustering tools. 

## So again... why razor?
Razor is the only tool that does the following:

1. Fairly agnostic to the accompanying tools. 
2. Has a simple API that does the heavy lifting of OS provisioning called "Tasks" which is built on Ruby erb templating.  
3. Provides connection points between system management tool-sets using what are called "Brokers". 

With this framework we were able to build a system that can install systems ranging from clusters of Xen Hypervisors to individual Windows 2012 R2 servers. That is a powerful tool. Its made even more powerfully when the tool-set is designed to utilize modern [CI](http://en.wikipedia.org/wiki/Continuous_integration) and [CD](http://en.wikipedia.org/wiki/Continuous_delivery) workflows.
